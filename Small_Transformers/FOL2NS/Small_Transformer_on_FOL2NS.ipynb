{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06543f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import re\n",
    "import string\n",
    "import json\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from torchmetrics.classification import MulticlassF1Score\n",
    "import sklearn.metrics\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3c02925",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from math import *\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "from glob import glob\n",
    "from tqdm.auto import tqdm\n",
    "from torch.optim import AdamW\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abef9cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import set_seed\n",
    "import random\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9ea358",
   "metadata": {},
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c4af54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tok_to_idx(toks):\n",
    "    return{tok: idx for idx, tok in enumerate(toks)}\n",
    "\n",
    "def idx_to_tok(toks):\n",
    "    idx_dict = tok_to_idx(toks)\n",
    "    return {idx: tok for tok, idx in idx_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44e5f847",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenization(data, without_comma):\n",
    "    output = []\n",
    "    for dic in data:\n",
    "        tok_re = re.compile(r\"\\b\\w+\\b|[^\\w\\s]\")\n",
    "        tok = tok_re.findall(dic['FOL2NS'])\n",
    "        if without_comma:\n",
    "            tok = [t for t in tok if t!=\",\" ]\n",
    "        tok = [\"<bos>\"] + tok\n",
    "        output.append(tok)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3249e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detokenization(idx_seq, idx2tok):\n",
    "    tokens = [idx2tok[i] for i in idx_seq]\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a69e0a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapping(data, tok2idx, without_comma):\n",
    "    output = []\n",
    "    tokizer = tokenization(data, without_comma)\n",
    "    for i in tokizer:\n",
    "        item = []\n",
    "        for tok in i:\n",
    "            idx = tok2idx[tok]\n",
    "            item.append(idx)\n",
    "        output.append(item)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d153317",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_data(data, tok2idx, without_comma):\n",
    "    mapped_ids = mapping(data, tok2idx, without_comma)\n",
    "    for org, ids in zip(data, mapped_ids):\n",
    "        org[\"input_ids\"] = ids\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07fd82ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding(batch_data, tok2idx):\n",
    "    FOL, QD = zip(*batch_data)\n",
    "    labels = torch.tensor(QD, dtype=torch.long)\n",
    "    FOL_ts = [torch.tensor(f, dtype=torch.long) for f in FOL]\n",
    "    inputs = pad_sequence(FOL_ts, batch_first=True, padding_value=tok2idx['<pad>'])\n",
    "    \n",
    "    return {\"input_ids\": inputs,\n",
    "            \"labels\": labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "938faf12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data_name, without_comma):\n",
    "    data = []\n",
    "    with open(data_name, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            item = json.loads(line)\n",
    "            data.append(item)\n",
    "            \n",
    "    data_new = reconstruct_data(data, tok2idx, without_comma)\n",
    "    inputs = [item[\"input_ids\"] for item in data_new]\n",
    "    labels = [(int(item[\"QD\"])-1) for item in data_new]\n",
    "    pairs = list(zip(inputs, labels))\n",
    "    train_pairs, valid_pairs = train_test_split(pairs, test_size=0.2, random_state=42)\n",
    "    train_loader = DataLoader(train_pairs, batch_size=32, drop_last = True, collate_fn = lambda batch: padding(batch, tok2idx))\n",
    "    valid_loader = DataLoader(valid_pairs, batch_size=32, drop_last = True, collate_fn = lambda batch: padding(batch, tok2idx))\n",
    "    \n",
    "    return train_loader, valid_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "34218f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 128\n",
    "person = [\n",
    "    'Accountants', 'Actors', 'Actuaries', 'Adults', 'Advisors', 'Agents', 'Allergists', 'Analysts',\n",
    "    'Anthropologists', 'Archaeologists', 'Artists', 'Astronomers', 'Athletes', 'Attackers', 'Audiologists', 'Auditors',\n",
    "    'Babies', 'Bailiffs', 'Bakers', 'Ballerinas', 'Barbers', 'Bartenders', 'Bloggers', 'Boxers',\n",
    "    'Breadwinners', 'Butchers', 'Butlers', 'Captains', 'Cartographers', 'Cashiers', 'Chiropractors', 'Cleaners',\n",
    "    'Clerks', 'Conductors', 'Cooks', 'Cricketers', 'Crooks', 'Cyclists', 'Cynics', 'Dancers',\n",
    "    'Defenders', 'Dentists', 'Directors', 'Drillers', 'Drivers', 'Economists', 'Electricians', 'Engineers',\n",
    "    'Epidemiologists', 'Experts', 'Farmers', 'Fighters', 'Firemen', 'Fishermen', 'Footballers', 'Foresters',\n",
    "    'Ghosts', 'Grandmasters', 'Guests', 'Gymnasts', 'Hairdressers', 'Helpers', 'Historians', 'Hosts',\n",
    "    'Jewelers', 'Judges', 'Jurors', 'Kings', 'Knights', 'Lawyers', 'Lecturers', 'Librarians',\n",
    "    'Machinists', 'Masters', 'Mathematicians', 'Mechanics', 'Monologists', 'Musicians', 'Opticians', 'Painters',\n",
    "    'Parents', 'Patients', 'Pavers', 'Philosophers', 'Photographers', 'Physicians', 'Physicists', 'Pilots',\n",
    "    'Players', 'Playmakers', 'Plumbers', 'Poets', 'Policemen', 'Princes', 'Princesses', 'Principals',\n",
    "    'Prisoners', 'Professors', 'Psychologists', 'Publishers', 'Quants', 'Queens', 'Researchers', 'Roofers',\n",
    "    'Sailors', 'Scholars', 'Scientists', 'Scorers', 'Scribes', 'Secretaries', 'Settlers', 'Sheriffs',\n",
    "    'Soldiers', 'Strategists', 'Students', 'Surgeons', 'Surveyors', 'Teachers', 'Technicians', 'Therapists',\n",
    "    'Tourists', 'Traders', 'Veterinarians', 'Violinists', 'Visitors', 'Waiters', 'Warlords', 'Witches']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7e426f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 88\n",
    "thing = [\n",
    "    \"Apples\", \"Amulets\", \"Arrows\", \"Axes\", \"Backpacks\", \"Batteries\", \"Belts\", \"Bells\", \"Boots\",\n",
    "    \"Bolts\", \"Books\", \"Boxes\", \"Bowls\", \"Bows\", \"Bracelets\", \"Bracers\", \"Brooches\", \"Buckets\",\n",
    "    \"Candles\", \"Chalices\", \"Chests\", \"Cogs\", \"Coins\", \"Compasses\", \"Crates\", \"Crossbows\",\n",
    "    \"Crowbars\", \"Cups\", \"Daggers\", \"Drums\", \"FishingRods\", \"Flasks\", \"Flutes\", \"Gauntlets\",\n",
    "    \"Gems\", \"Glasses\", \"Gloves\", \"Greaves\", \"Hammers\", \"Hats\", \"Helmets\", \"Horns\",\n",
    "    \"Jars\", \"Keys\", \"Lanterns\", \"Lockets\", \"Maps\", \"Masks\", \"Mirrors\", \"Nets\",\n",
    "    \"Necklaces\", \"Notebooks\", \"OilFlasks\", \"Orbs\", \"Paintings\", \"Pauldrons\", \"Plates\", \"Pliers\",\n",
    "    \"Pears\", \"Pipes\", \"Pouches\", \"Potions\", \"Quills\", \"Ropes\", \"Runes\", \"Sashes\", \"Satchels\",\n",
    "    \"ScrollCases\", \"Scrolls\", \"Saws\", \"Screwdrivers\", \"Shields\", \"Shovels\", \"Spears\", \"Staffs\",\n",
    "    \"Statues\", \"SwordSheaths\", \"Swords\", \"Tablets\", \"Talismans\", \"Tongs\", \"Torches\", \"Trinkets\",\n",
    "    \"Trunks\", \"Vases\", \"Vials\", \"Wands\", \"Wrenches\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "028a94c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 98\n",
    "un_pre = [\n",
    "    'Active', 'Alert', 'Ambitious', 'Artistic', 'Bored', 'Brave', 'Busy', 'Calm',\n",
    "    'Careless', 'Cautious', 'Charming', 'Cheerful', 'Clever', 'Clumsy', 'Cold',\n",
    "    'Confident', 'Creative', 'Critical', 'Curious', 'Demanding', 'Determined',\n",
    "    'Diligent', 'Disorganized', 'Distracted', 'Efficient', 'Elegant', 'Energetic',\n",
    "    'Experienced', 'Fair', 'Fearless', 'Focused', 'Friendly', 'Funny', 'Generous',\n",
    "    'Graceful', 'Hardworking', 'Helpful', 'Honest', 'Humble', 'Idealistic',\n",
    "    'Impatient', 'Junior', 'Kind', 'Late', 'Lazy', 'Loyal', 'Messy', 'Modest',\n",
    "    'Motivated', 'Naive', 'Nervous', 'Neutral', 'New', 'Old', 'Open', 'Organized',\n",
    "    'Passionate', 'Patient', 'Picky', 'Polite', 'Pragmatic', 'Proud', 'Punctual',\n",
    "    'Quiet', 'Realistic', 'Rebellious', 'Relaxed', 'Reliable', 'Reserved', 'Rude',\n",
    "    'Selfish', 'Senior', 'Serious', 'Short', 'Shy', 'Silent', 'Skilled', 'Slow',\n",
    "    'Smart', 'Social', 'Strict', 'Strong', 'Stubborn', 'Stylish', 'Talented',\n",
    "    'Talkative', 'Tall', 'Thoughtful', 'Tired', 'Unfair', 'Unreliable',\n",
    "    'Unsocial', 'Visionary', 'Warm', 'Weak', 'Wise', 'Witty', 'Young'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "39518b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 88\n",
    "bin_pre = [\n",
    "    'Accompany', 'Accuse', 'Admire', 'Advise', 'Align', 'Approach', 'Argue', 'Assist',\n",
    "    'Betray', 'Blame', 'Brief', 'Challenge', 'Collaborate', 'Comment', 'Compare', 'Compete',\n",
    "    'Compliment', 'Confront', 'Consult', 'Contact', 'Convince', 'Criticize', 'Deceive', 'Demand',\n",
    "    'Discipline', 'Discuss', 'Dismiss', 'Doubt', 'Employ', 'Engage', 'Envy', 'Evaluate',\n",
    "    'Fire', 'Follow', 'Fund', 'Greet', 'Guide', 'Hate', 'Help', 'Ignore',\n",
    "    'Inform', 'Instruct', 'Insult', 'Interrupt', 'Invite', 'Involve', 'Judge', 'Know',\n",
    "    'Lecture', 'Like', 'Listen', 'Manage', 'Mentor', 'Monitor', 'Motivate', 'Negotiate',\n",
    "    'Notify', 'Observe', 'Oppose', 'Pay', 'Persuade', 'Praise', 'Prefer', 'Protect',\n",
    "    'Provoke', 'Punish', 'Question', 'Refer', 'Reject', 'Remind', 'Replace', 'Report',\n",
    "    'Request', 'Respect', 'Reward', 'Schedule', 'Scold', 'Shadow', 'Sponsor', 'Supervise',\n",
    "    'Support', 'Teach', 'Train', 'Trust', 'Undermine', 'Love', 'Value', 'Warn'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7166ad1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 35\n",
    "tern_pre = [\n",
    "    'Allocate', 'Assign', 'Award', 'Bring', 'Contribute',\n",
    "    'Convey', 'Consign', 'Delegate', 'Deliver', 'Dispatch', 'Distribute', 'Donate',\n",
    "    'Entrust', 'Explain', 'Forward', 'Furnish', 'Give', 'Grant', 'Hand', 'Introduce',\n",
    "    'Lend', 'Loan', 'Offer', 'Pass', 'Pay', 'Post', 'Present', 'Provide', 'Recommend',\n",
    "    'Sell', 'Send', 'Share', 'Show', 'Supply','Transfer'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "26d59720",
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol = ['<pad>','<bos>',',','.']\n",
    "quanti = ['some', 'all', 'Some', 'All']\n",
    "LO = ['and', 'or', 'implies']\n",
    "others = ['the', 'a', 'to', 'by', 'are', 'of', 'in', 'which', 'that', 'It', 'it', 'is', 'who', 'day', 'careful', 'inspection', \n",
    "          'with', 'without', 'will', 'after', 'After', 'end', 'occasionally', 'effectively', 'regularly', 'timely', 'case', \n",
    "         'planning', 'manner', 'great', 'care', 'exception']\n",
    "predicate = person + thing + un_pre + bin_pre + tern_pre\n",
    "predicate = [i.lower() for i in predicate]\n",
    "toks = symbol + quanti + predicate + LO + others\n",
    "enc_voc_size = len(toks)\n",
    "tok2idx = tok_to_idx(toks)\n",
    "idx2tok = idx_to_tok(toks)\n",
    "src_pad_idx = tok2idx['<pad>']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5866226",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "06edc358",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embeddings(nn.Module):\n",
    "    def __init__(self, vocb_size, max_len, d_model, device, dropout):\n",
    "        super().__init__()\n",
    "        self.we = nn.Embedding(vocb_size, d_model)\n",
    "        self.pe = nn.Parameter(torch.randn(1, max_len, d_model))\n",
    "        self.device = device\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.scale = math.sqrt(d_model)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len = x.size()\n",
    "        tok = self.we(x) * self.scale\n",
    "        pos = self.pe[:, :seq_len, :].to(device=self.device)\n",
    "        embedding = tok + pos.expand(batch_size, seq_len, -1)\n",
    "        return self.dropout(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "092996e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocb_size, max_len, d_model, n_heads, n_classes, dropout):\n",
    "        super().__init__()\n",
    "        self.emb = Embeddings(vocb_size, max_len, d_model, device, dropout)\n",
    "        self.encoder = TransformerEncoderWithHooks(d_model=d_model, \n",
    "                                              nhead=n_heads, \n",
    "                                              num_layers=n_layers, \n",
    "                                              dim_feedforward=2048, \n",
    "                                              dropout=0)\n",
    "        \n",
    "        self.classifierhead = nn.Linear(d_model, n_classes)\n",
    "    \n",
    "    def forward(self, src, src_mask=None, src_key_padding_mask=None):\n",
    "        emb = self.encoder(self.emb(src), src_mask=src_mask, src_key_padding_mask=src_key_padding_mask)\n",
    "        return torch.tanh(self.classifierhead(emb[:, 0, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cdfb478e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_attention_weights_hook_generator(layer_idx):\n",
    "\n",
    "    def hook(module, input, output):\n",
    "        if module.training:\n",
    "            return None\n",
    "        if not isinstance(output, tuple) or len(output) < 2 or output[1] is None:\n",
    "            raise ValueError(f'Could not find attention weights in the output of the self-attention module {layer_idx}!')\n",
    "        \n",
    "        attention_weights_store[layer_idx] = output[1].detach().cpu()\n",
    "    return hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5d895dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTransformerEncoderLayer(nn.TransformerEncoderLayer):\n",
    "\n",
    "    def _sa_block(self, x, attn_mask, key_padding_mask, **kwargs):\n",
    "        x, attn_weights = self.self_attn(\n",
    "            x, x, x,\n",
    "            attn_mask=attn_mask,\n",
    "            key_padding_mask=key_padding_mask,\n",
    "            need_weights=True,\n",
    "            average_attn_weights=False,  \n",
    "            **kwargs\n",
    "        )\n",
    "        return self.dropout1(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c2bfb6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoderWithHooks(nn.Module):\n",
    "    def __init__(self, d_model, nhead, num_layers, dim_feedforward, dropout):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.nhead = nhead\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.layers = nn.ModuleList()\n",
    "        for i in range(num_layers):\n",
    "            layer = MyTransformerEncoderLayer(\n",
    "                d_model=d_model,\n",
    "                nhead=nhead,\n",
    "                dim_feedforward=dim_feedforward,\n",
    "                dropout=dropout,\n",
    "                batch_first=True   \n",
    "            )\n",
    "        \n",
    "            mha_module = layer.self_attn \n",
    "\n",
    "            mha_module.register_forward_hook(\n",
    "                save_attention_weights_hook_generator(i)) \n",
    "            self.layers.append(layer)\n",
    "\n",
    "        self.norm = nn.LayerNorm(d_model) \n",
    "\n",
    "    def forward(self, src, src_mask=None, src_key_padding_mask=None):\n",
    "        output = src\n",
    "        attention_weights_store.clear()\n",
    "        for layer in self.layers:\n",
    "             output = layer(output, src_mask=src_mask,\n",
    "                            src_key_padding_mask=src_key_padding_mask)\n",
    "\n",
    "        output = self.norm(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d58a9f",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "be8017c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_data, model, optimizer, loss_fn, device):  \n",
    "    model.train()\n",
    "    train_loss = torch.empty(len(train_data))\n",
    "    for batch_step, items in tqdm(enumerate(train_data),\n",
    "                              total=len(train_data),\n",
    "                              desc='Train',\n",
    "                              leave=False):\n",
    "        optimizer.zero_grad()\n",
    "        inputs = items[\"input_ids\"].to(device)\n",
    "        gold = items[\"labels\"].to(device)\n",
    "        mask = (inputs==0)\n",
    "        logits = model(src=inputs, src_mask=None, src_key_padding_mask=mask)\n",
    "        loss = loss_fn(logits, gold) \n",
    "        loss.backward() \n",
    "        optimizer.step() \n",
    "        train_loss[batch_step]= loss.item()\n",
    "    return train_loss.mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8da24542",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(valid_data, model, loss_fn, device, topk): \n",
    "    model.eval()\n",
    "    macroScore = MulticlassF1Score(num_classes=4, average='macro').to(device)\n",
    "    perScore = MulticlassF1Score(num_classes=4, average=None).to(device)\n",
    "    \n",
    "    all_probs, all_preds, topk_probs  = [], [], []\n",
    "    valid_loss = torch.empty(len(valid_data))\n",
    "    valid_accuracy = torch.empty(len(valid_data))\n",
    "    valid_macroF1 = torch.empty(len(valid_data))\n",
    "    valid_perF1 = torch.empty(len(valid_data), 4)\n",
    "    \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_step, items in tqdm(enumerate(valid_data),\n",
    "                                total=len(valid_data),\n",
    "                                desc='Eval',\n",
    "                                leave=False):\n",
    "            \n",
    "            inputs = items[\"input_ids\"].to(device)\n",
    "            gold = items[\"labels\"].to(device)\n",
    "            mask = (inputs==0)\n",
    "            logits = model(src=inputs, src_mask=None, src_key_padding_mask=mask)\n",
    "            preds = torch.argmax(logits, dim=-1)\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            topk_val, topk_idx = probs.topk(topk, dim=-1)\n",
    "            \n",
    "            all_preds.append(preds)\n",
    "            topk_probs.append((topk_val, topk_idx))\n",
    "            \n",
    "            loss = loss_fn(logits, gold)\n",
    "            macroF1 = macroScore(preds, gold)\n",
    "            perF1 = perScore(preds, gold)\n",
    "\n",
    "            valid_loss[batch_step] = loss.item()\n",
    "            valid_accuracy[batch_step] = ((preds == gold).sum().item()) / gold.size(0)\n",
    "            valid_macroF1[batch_step] = macroF1\n",
    "            valid_perF1[batch_step] = perF1\n",
    "    return valid_loss.mean().item(), valid_accuracy.mean().item(), valid_macroF1.mean().item(), valid_perF1.mean(dim=0), all_preds, topk_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2ddfbfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(data_name, epoch, best_acc, early_stop, topk):  \n",
    "    train_data, valid_data = preprocess(\"FOL2NS.json\") \n",
    "    train_losses, valid_losses, valid_accuracies = [], [], []\n",
    "    valid_perF1s, valid_macroF1s = [], []\n",
    "    lr_string = abs(int(log10(lr)))\n",
    "    last_improve = 0\n",
    "    print(data_name)\n",
    "    for step in tqdm(range(epoch)):\n",
    "        train_loss = train(train_data=train_data, model=model, optimizer=optimizer, loss_fn=loss_fn, device=device)  \n",
    "        valid_loss, valid_acc, valid_macroF1, valid_perF1, all_preds, topk_probs = validate(valid_data=valid_data, model=model, loss_fn=loss_fn, device=device, topk=topk)\n",
    "        print(f'Epoch: {step + 1}, Train Loss: {train_loss:.2f}, Val Loss: {valid_loss:.2f}')\n",
    "        print(f'Val Accuracy: {valid_acc:.2f}, Val macroF1: {valid_macroF1:.2f}')\n",
    "        if isinstance(valid_perF1, torch.Tensor):\n",
    "            valid_perF1_ls = valid_perF1.cpu().tolist()\n",
    "        else:                    \n",
    "            valid_perF1_ls = list(valid_perF1)\n",
    "\n",
    "        print(f'Val_F1 QD=1: {valid_perF1_ls[1]:.2f}, ',\n",
    "                f'QD=2: {valid_perF1_ls[2]:.2f}, ',\n",
    "                f'QD=3: {valid_perF1_ls[3]:.2f}')\n",
    "        train_losses.append(train_loss)\n",
    "        valid_losses.append(valid_loss)\n",
    "        valid_accuracies.append(valid_acc)\n",
    "        valid_perF1s.append(valid_perF1_ls)\n",
    "        valid_macroF1s.append(valid_macroF1)\n",
    "        \n",
    "        if valid_acc > best_acc:\n",
    "            best_acc = valid_acc\n",
    "            last_improve = step\n",
    "            \n",
    "            for path in glob('*.pt'):\n",
    "                os.remove(path)\n",
    "            torch.save({'best_model': model.state_dict()}, \n",
    "                        f'{data_name}_epoch{step+1}_lr{lr_string}_{valid_acc:.2f}.pt')\n",
    "        else:\n",
    "            if step - last_improve == early_stop:\n",
    "                print(f'Early stopping: no improvement for {early_stop} epochs.')\n",
    "                break\n",
    "        \n",
    "    plt.plot(train_losses, label='Train Loss')\n",
    "    plt.plot(valid_losses, label='Valid Loss')\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    plt.plot(valid_accuracies, label='Valid Accuracy')\n",
    "    plt.plot(valid_macroF1s, label='Valid macro_F1score')\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Metric\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    for i in range(3):\n",
    "        per_class = [per[i] for per in valid_perF1s]\n",
    "        plt.plot(range(1, len(valid_perF1s)+1), per_class, label=f'QD={i+1}')\n",
    "    \n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Per-class F1 Score')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "                 \n",
    "    return all_preds, topk_probs,valid_accuracies, valid_macroF1s, valid_perF1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bff540d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(path, device,model):\n",
    "    state = torch.load(path, map_location=device)\n",
    "    model.load_state_dict(state['best_model'])\n",
    "    \n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6d66c5",
   "metadata": {},
   "source": [
    "## Function: Attention Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a97cd999",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_attention_weights():\n",
    "    print(\"\\n--- Stored Attention Weights ---\")\n",
    "    if not attention_weights_store:\n",
    "        print(\"No attention weights were captured.\")\n",
    "    else:\n",
    "        for layer_idx, weights in attention_weights_store.items():\n",
    "            # Expected shape: (batch_size, num_heads, seq_len, seq_len)\n",
    "            print(f\"Layer {layer_idx}: Weights = {weights.shape}\")\n",
    "            # Check that attention weights in the first input sum to 1.\n",
    "            print(f\"Weight row sums = {weights[0].sum(dim=-1).flatten()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "52564c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attetion_info(sample_idx, all_preds, with_pad=False):\n",
    "    pad_tok = \"<pad>\"\n",
    "    input_id = last_inputs[sample_idx].tolist()\n",
    "    input_token = detokenization(input_id, idx2tok)\n",
    "    tokens = [idx2tok[i] for i in input_id]\n",
    "    if with_pad:\n",
    "        tok = [\"-\" if t == pad_tok else t for t in tokens]\n",
    "    else:\n",
    "        tok = [t for t in tokens if t != pad_tok]\n",
    "    label = last_labels[sample_idx].tolist()\n",
    "    last_preds = all_preds[-1]\n",
    "    pred = last_preds[sample_idx].tolist()\n",
    "    print(\"Input token:\", \" \".join(tok))\n",
    "    print(\"Label:\", (int(label)+1))\n",
    "    print(\"Prediction:\", pred+1)\n",
    "    \n",
    "    for layer_idx, weights in attention_weights_store.items():\n",
    "        batch_size, head, seq_len, _ = weights.shape\n",
    "        x = np.arange(len(tok))\n",
    "        \n",
    "        for h in range(head):\n",
    "            attn = weights[sample_idx, h, :, :].numpy()\n",
    "            fig = plt.figure(figsize=(8,8))\n",
    "            imshow = plt.imshow(attn[:len(tok), :len(tok)], aspect='auto')\n",
    "            plt.xticks(x, tok, fontsize=10)\n",
    "            plt.yticks(x, tok, fontsize=10)\n",
    "            plt.title(f\"Sample:{sample_idx}, Layer:{layer_idx}, Head:{h}\")\n",
    "            plt.xlabel(\"Key Position\")\n",
    "            plt.ylabel(\"Query Position\")\n",
    "            plt.xticks(rotation=45, ha='right')\n",
    "            fig.colorbar(imshow)\n",
    "            \n",
    "            filename = f\"type1_{n_layers}L{n_heads}H_Sample{sample_idx}_L{layer_idx}H{h}.png\"   \n",
    "            plt.savefig(filename, dpi=800, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "87d49040",
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_case(all_preds, topk_probs):\n",
    "    last_preds = all_preds[-1]\n",
    "    top, logit_idx= topk_probs[-1]\n",
    "    logit_idx = logit_idx+1\n",
    "    for idx, item in enumerate(last_preds):\n",
    "        if item != (last_labels[idx]):\n",
    "            print(f\"-----Error{idx}:{all_token[idx]}-----\")\n",
    "            print(f\"label:{last_labels[idx]+1}, prediction:{item+1}.\")\n",
    "            print(f\"logits:{top[idx].tolist()},logit_idx:{logit_idx[idx].tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "661a73c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_case(all_preds, topk_probs):\n",
    "    last_preds = all_preds[-1]\n",
    "    top, logit_idx= topk_probs[-1]\n",
    "    logit_idx = logit_idx\n",
    "    for idx, item in enumerate(last_preds):\n",
    "        if item == (last_labels[idx]):\n",
    "            print(f\"-----Correct{idx}:{all_token[idx]}-----\")\n",
    "            print(f\"label:{last_labels[idx]+1}, prediction:{item+1}.\")\n",
    "            print(f\"logits:{top[idx].tolist()},logit_idx:{logit_idx[idx].tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18804f4a",
   "metadata": {},
   "source": [
    "# Run Main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9191c24f",
   "metadata": {},
   "source": [
    "## Parameter setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "84664a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model parameter \n",
    "batch_size = 32\n",
    "max_len = 256\n",
    "d_model = 256\n",
    "n_classes = 4\n",
    "dropout = 0\n",
    "topk = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "983f9194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer parameter \n",
    "early_stop = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c1fdae14",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" # if torch.cuda.is_available() else \"cpu\"\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af90fbb",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5f20f454",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = \"FOL2NS.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3a55c64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-5\n",
    "epoch = 15\n",
    "n_layers = 2\n",
    "n_heads = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefe622f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Classifier(vocb_size=enc_voc_size,\n",
    "                   max_len=max_len,\n",
    "                   d_model=d_model, \n",
    "                   n_heads=n_heads, \n",
    "                   n_classes=n_classes, \n",
    "                   dropout=dropout).to(device)\n",
    "\n",
    "optimizer = AdamW(params=model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "dad2ba87",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache() \n",
    "attention_weights_store = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e0d137",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds, topk_probs,valid_accuracies, valid_macroF1s, valid_perF1s = main(data_name, epoch, float(\"-inf\"), early_stop, topk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea35774",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_confusion_matrix(loader, all_preds, display_labels=[1,2,3], figsize=(6,6)):\n",
    "    golds = []\n",
    "    for batch in loader:\n",
    "        lbl = batch['labels'] if isinstance(batch, dict) else batch[1]\n",
    "        golds.append(lbl.detach().cpu().numpy())\n",
    "    golds = np.concatenate(golds, axis=0)\n",
    "\n",
    "    preds_list = []\n",
    "    for p in all_preds:\n",
    "        if torch.is_tensor(p):\n",
    "            preds_list.append(p.detach().cpu().numpy())\n",
    "        else:\n",
    "            preds_list.append(np.array(p))\n",
    "    preds = np.concatenate(preds_list, axis=0)\n",
    "\n",
    "    assert preds.shape[0] == golds.shape[0]\n",
    "\n",
    "    labels = np.unique(golds)\n",
    "    cm = confusion_matrix(golds, preds, labels=labels)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                                  display_labels=display_labels)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    disp.plot(ax=ax, cmap='Blues', colorbar=False)\n",
    "    ax.set_title(\"Confusion Matrix\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4c8518",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data = preprocess(data_name, without_comma=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66c64af",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_confusion_matrix(\n",
    "    loader=valid_data,   \n",
    "    all_preds=all_preds,  \n",
    "    display_labels=[\"QD=1\",\"QD=2\",\"QD=3\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3f4071",
   "metadata": {},
   "source": [
    "## Attention Heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db55cb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_token = []\n",
    "train_data, valid_data = preprocess(data_name, without_comma=True) \n",
    "last_batch = list(valid_data)[-1]\n",
    "last_inputs = last_batch[\"input_ids\"]\n",
    "last_labels = last_batch[\"labels\"]\n",
    "for i,eg in enumerate(last_inputs.tolist()):\n",
    "    input_token = detokenization(eg, idx2tok)\n",
    "    a = [\"\" if j==\"<pad>\" else j for j in input_token.split()]\n",
    "    a = \" \".join(a)\n",
    "    print(i, a)\n",
    "    all_token.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae06edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_case(all_preds, topk_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b60fc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "attetion_info(sample_idx=28, all_preds=all_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3327f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "attetion_info(sample_idx=19, all_preds=all_preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
